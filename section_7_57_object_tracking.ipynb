{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "* is the pattern of apparent motion of image objects between two consecutive frames caused by the movement of the object or the camera.\n",
    "\n",
    "## Assumptions\n",
    "* pixel intensities of an object do not change between the consecutive frames (e.g. a lightbulb that turns off and on between images will not be tracked)\n",
    "* neighbouring pixels have similar motion\n",
    "\n",
    "## How the algorithm works\n",
    "1. The optical flow methods in OpenCV will take a given set of points in a frame\n",
    "2. It will then attempt to find these points in the next frame\n",
    "\n",
    "## Methods: \n",
    "### Lucas-Kanade method - https://de.wikipedia.org/wiki/Lucas-Kanade-Methode :\n",
    "* computes optical flow for a sparse features set (-> points are given)\n",
    "\n",
    "### Gunner Farnersback's algorithm \n",
    "can be used to calculate dense optical flow.\n",
    "\n",
    "This algorithm calculates the flow for all points in an image.\n",
    "\n",
    "Only a movement (flow) will be highlighted, everything else will be colored black."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucas-Kanade Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_track_params = dict(maxCorners=10, qualityLevel=0.3, minDistance=7, blockSize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger motions can be detected by larger winsize but it is more sensitive to noise\n",
    "# maxLevel is based on pyarmid for image processing: https://en.wikipedia.org/wiki/Pyramid_(image_processing) \n",
    "# criteria we use both, speed (count) vs. accuracy of the algorithm (eps)\n",
    "lucas_kanade_params = dict(winSize=(200,200), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(cv2\u001b[38;5;241m.\u001b[39mCAP_PROP_FPS, \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m      3\u001b[0m ret, prev_frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 5\u001b[0m prev_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# # Points to track\u001b[39;00m\n\u001b[1;32m      8\u001b[0m prev_points \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgoodFeaturesToTrack(prev_gray, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcorner_track_params)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Points to track\n",
    "prev_points = cv2.goodFeaturesToTrack(prev_gray, mask=None, **corner_track_params)\n",
    "\n",
    "mask = np.zeros_like(prev_frame) # visualization - zeros with the same size of the prev_frame\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # calculating the optical flow on the actual frame\n",
    "    next_points, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prev_points, None, **lucas_kanade_params)\n",
    "\n",
    "    good_new = next_points[status==1]\n",
    "    good_prev = prev_points[status==1]\n",
    "\n",
    "    for i, (new, prev) in enumerate(zip(good_new, good_prev)):\n",
    "        x_new, y_new = new.ravel() # reshape / flattening out an array -> 2d to 1d\n",
    "        x_prev, y_prev = prev.ravel()\n",
    "\n",
    "        mask = cv2.line(mask, (x_new, y_new), (x_prev, y_prev), (0,255,0), 3)\n",
    "        frame = cv2.circle(frame, (x_new, y_new), 8, (0,0,255), -1)\n",
    "    img = cv2.add(frame, mask)\n",
    "    cv2.imshow(\"tracking\", img)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    prev_gray = frame_gray.copy()\n",
    "\n",
    "    prev_points = good_new.reshape(-1,1,2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
